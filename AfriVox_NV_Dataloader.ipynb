{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2lq3IrM24U3",
        "outputId": "de64ec5b-85be-4909-c9b3-7f8404ea0809"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/491.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m450.6/491.4 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/193.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WORK_DIR = \".\"\n",
        "import sys\n",
        "sys.path.append(WORK_DIR)"
      ],
      "metadata": {
        "id": "5W_oRk8M2fcC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "N-EgPzY22GCl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from dataset import FleursDataset, NaijaVoices\n",
        "from collators import DataCollatorSpeechSeq2SeqWithPadding\n",
        "from preprocessing import clean_text, load_audio_file, AudioConfig"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    WhisperForConditionalGeneration,\n",
        "    WhisperProcessor,\n",
        "    WhisperFeatureExtractor,\n",
        "    WhisperTokenizer,\n",
        "    set_seed,\n",
        "    Seq2SeqTrainingArguments,\n",
        ")"
      ],
      "metadata": {
        "id": "fcbzpmfN6gEr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "language_iso_map = {\"yo\": \"yoruba\", \"ig\": \"igbo\", \"ha\": \"hausa\"}\n",
        "\n",
        "TOKINIZER_PATH = \"openai/whisper-base\"\n",
        "MODEL_PATH = \"openai/whisper-base\"\n",
        "LANGUAGE = 'yo'\n",
        "\n",
        "processor = WhisperProcessor.from_pretrained(\n",
        "    TOKINIZER_PATH,\n",
        "    task=\"transcribe\",\n",
        "    language=LANGUAGE,\n",
        ")\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(\n",
        "    TOKINIZER_PATH\n",
        ")\n",
        "tokenizer = WhisperTokenizer.from_pretrained(\n",
        "    TOKINIZER_PATH,\n",
        "    task=\"transcribe\",\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb4bzZYW6I1s",
        "outputId": "dffa017c-c679-4ce4-b2b5-f9ea9c842b90"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_file = 'PATH TO CSV FILE FOR EITHER TRAIN, DEV OR TEST'\n",
        "audio_dir = 'PATH TO AUDIO FOLDER'\n",
        "\n",
        "nv_dataset = NaijaVoices(\n",
        "    data_file=data_file,\n",
        "    audio_dir=audio_dir,\n",
        "    processor=processor,\n",
        "    feature_extractor=feature_extractor,\n",
        "    tokenizer=tokenizer,\n",
        "    max_audio_len_secs=30,\n",
        ")"
      ],
      "metadata": {
        "id": "6YExrxoM8SqY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NaijaVoices??"
      ],
      "metadata": {
        "id": "whlPfoH9_ZFz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(nv_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRxMtqpE_DBU",
        "outputId": "92031d2a-d468-4d33-bd79-d9851cf89896"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/afrivox/emnlp_nv_dataset/emnlp_nv_dataset/20231214170614-29-235-52695-windo-gb-ala-ga-echekwa-gb.wav not found [Errno 5] Input/output error: '/content/drive/MyDrive/afrivox/emnlp_nv_dataset/emnlp_nv_dataset/20231214170614-29-235-52695-windo-gb-ala-ga-echekwa-gb.wav'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_features': array([[ 1.4473784 ,  1.4492252 ,  1.451394  , ..., -0.52047443,\n",
              "         -0.52047443, -0.52047443],\n",
              "        [ 1.1810598 ,  1.1870606 ,  1.1780188 , ..., -0.52047443,\n",
              "         -0.52047443, -0.52047443],\n",
              "        [ 0.7026305 ,  0.8948299 ,  0.7760446 , ..., -0.52047443,\n",
              "         -0.52047443, -0.52047443],\n",
              "        ...,\n",
              "        [ 0.8677349 ,  0.8556884 ,  0.791379  , ..., -0.52047443,\n",
              "         -0.52047443, -0.52047443],\n",
              "        [ 0.8607256 ,  0.878031  ,  0.8706415 , ..., -0.52047443,\n",
              "         -0.52047443, -0.52047443],\n",
              "        [ 0.8041186 ,  0.9518909 ,  0.92550176, ..., -0.52047443,\n",
              "         -0.52047443, -0.52047443]], dtype=float32),\n",
              " 'input_lengths': 80,\n",
              " 'labels': [50258,\n",
              "  50359,\n",
              "  50363,\n",
              "  6166,\n",
              "  9309,\n",
              "  486,\n",
              "  1009,\n",
              "  2371,\n",
              "  264,\n",
              "  1032,\n",
              "  13,\n",
              "  50257]}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ajsXkLTFAdMB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}